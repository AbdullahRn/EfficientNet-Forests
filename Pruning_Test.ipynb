{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi3iLVaQOdXc"
      },
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "#  SETUP — Kaggle Notebook Version (NO COLAB, NO kaggle.json)\n",
        "# ================================================================\n",
        "\n",
        "import os, json, random\n",
        "from pathlib import Path\n",
        "import copy  # <-- NEW: for safe rollback on bad pruning\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "# -------------------------\n",
        "#  Dataset paths (Kaggle)\n",
        "# -------------------------\n",
        "DATA_ROOT = \"/kaggle/input/paribahan-bd\"\n",
        "LOCAL_VEHICLES_DIR = os.path.join(DATA_ROOT, \"Local-Vehicles\", \"Local-Vehicles\")\n",
        "\n",
        "print(\"DATA ROOT CONTENTS:\", os.listdir(DATA_ROOT))\n",
        "print(\"VEHICLE CLASS FOLDERS:\", os.listdir(LOCAL_VEHICLES_DIR))\n",
        "\n",
        "# -------------------------\n",
        "#  Reproducibility\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# -------------------------\n",
        "#  Device\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ================================================================\n",
        "#  TRANSFORMS\n",
        "# ================================================================\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std =[0.229, 0.224, 0.225],\n",
        "    ),\n",
        "])\n",
        "\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std =[0.229, 0.224, 0.225],\n",
        "    ),\n",
        "])\n",
        "\n",
        "# ================================================================\n",
        "#  LOAD DATA\n",
        "# ================================================================\n",
        "base_dataset = datasets.ImageFolder(root=LOCAL_VEHICLES_DIR, transform=None)\n",
        "print(\"Found classes:\", base_dataset.classes)\n",
        "NUM_CLASSES = len(base_dataset.classes)\n",
        "\n",
        "indices = np.arange(len(base_dataset))\n",
        "labels = np.array(base_dataset.targets)\n",
        "\n",
        "train_idx, tmp_idx, y_train, y_tmp = train_test_split(\n",
        "    indices, labels, test_size=0.3, random_state=SEED, stratify=labels\n",
        ")\n",
        "val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "    tmp_idx, y_tmp, test_size=0.5, random_state=SEED, stratify=y_tmp\n",
        ")\n",
        "\n",
        "print(f\"TOTAL SAMPLES: {len(base_dataset)}\")\n",
        "print(f\"TRAIN: {len(train_idx)} | VAL: {len(val_idx)} | TEST: {len(test_idx)}\")\n",
        "\n",
        "# ================================================================\n",
        "#  CUSTOM DATASET\n",
        "# ================================================================\n",
        "class IndexedImageFolder(Dataset):\n",
        "    def __init__(self, base_ds, indices, transform=None):\n",
        "        self.base = base_ds\n",
        "        self.indices = list(indices)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        img, label = self.base[self.indices[i]]\n",
        "        img = img.convert(\"RGB\")  # ensure RGB\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "train_dataset_global = IndexedImageFolder(base_dataset, train_idx, transform=train_transform)\n",
        "val_dataset_global   = IndexedImageFolder(base_dataset, val_idx,   transform=eval_transform)\n",
        "test_dataset_global  = IndexedImageFolder(base_dataset, test_idx,  transform=eval_transform)\n",
        "\n",
        "train_loader_global = DataLoader(train_dataset_global, batch_size=BATCH_SIZE,\n",
        "                                 shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader_global   = DataLoader(val_dataset_global, batch_size=BATCH_SIZE,\n",
        "                                 shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader_global  = DataLoader(test_dataset_global, batch_size=BATCH_SIZE,\n",
        "                                 shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# ================================================================\n",
        "#  EXPERT MODELS (EfficientNet B0/B1/B2)\n",
        "# ================================================================\n",
        "EXPERT_BACKBONES = [\"efficientnet_b0\", \"efficientnet_b1\", \"efficientnet_b2\"]\n",
        "NUM_EXPERTS = len(EXPERT_BACKBONES)\n",
        "BOOTSTRAP_RATIO = 0.7\n",
        "\n",
        "TRIAL_EPOCHS = 1\n",
        "FULL_EPOCHS  = 2\n",
        "\n",
        "LAMBDA_GL = 1e-5\n",
        "PRUNE_AMOUNT = 0.3\n",
        "PRUNE_FT_EPOCHS = 1\n",
        "\n",
        "KD_TEMPERATURE = 4.0\n",
        "KD_ALPHA = 0.3\n",
        "KD_EPOCHS = 3\n",
        "\n",
        "LR_EXPERT = 1e-4\n",
        "LR_STUDENT = 1e-3\n",
        "\n",
        "criterion_ce = nn.CrossEntropyLoss()\n",
        "\n",
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def group_lasso_penalty(model):\n",
        "    gl = 0.0\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            w = m.weight\n",
        "            w_norm = w.pow(2).sum(dim=(1, 2, 3)).sqrt()\n",
        "            gl += w_norm.sum()\n",
        "    return gl\n",
        "\n",
        "def build_efficientnet_expert(name, num_classes):\n",
        "    if name == \"efficientnet_b0\":\n",
        "        m = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "    elif name == \"efficientnet_b1\":\n",
        "        m = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.IMAGENET1K_V1)\n",
        "    elif name == \"efficientnet_b2\":\n",
        "        m = models.efficientnet_b2(weights=models.EfficientNet_B2_Weights.IMAGENET1K_V1)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown EfficientNet variant\")\n",
        "\n",
        "    in_features = m.classifier[-1].in_features\n",
        "    m.classifier[-1] = nn.Linear(in_features, num_classes)\n",
        "    return m.to(device)\n",
        "\n",
        "\n",
        "experts = []\n",
        "for name in EXPERT_BACKBONES:\n",
        "    model = build_efficientnet_expert(name, NUM_CLASSES)\n",
        "    print(f\"Built expert {name} with {count_params(model)/1e6:.2f}M params\")\n",
        "    experts.append(model)\n",
        "\n",
        "# ================================================================\n",
        "#  TRAINING FUNCTIONS\n",
        "# ================================================================\n",
        "def train_one_epoch_single_model(model, dataloader, optimizer, criterion, device, lambda_gl=0.0):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(images)\n",
        "        ce_loss = criterion(out, labels)\n",
        "\n",
        "        loss = ce_loss + lambda_gl * group_lasso_penalty(model)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += ce_loss.item() * images.size(0)\n",
        "        total_correct += (out.argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return total_loss / total, total_correct / total\n",
        "\n",
        "\n",
        "def evaluate_single_model(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            out = model(images)\n",
        "            loss = criterion(out, labels)\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            total_correct += (out.argmax(1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return total_loss / total, total_correct / total\n",
        "\n",
        "def structured_channel_prune(model, amount):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            prune.ln_structured(m, name=\"weight\", amount=amount, n=2, dim=0)\n",
        "            prune.remove(m, \"weight\")\n",
        "\n",
        "# ================================================================\n",
        "#  TRAIN EXPERT MODELS\n",
        "# ================================================================\n",
        "expert_val_scores = []\n",
        "\n",
        "for i, expert in enumerate(experts):\n",
        "    print(f\"\\n=== Training Expert {i+1}/{NUM_EXPERTS} ===\")\n",
        "\n",
        "    n_train = len(train_dataset_global)\n",
        "    sub_size = int(BOOTSTRAP_RATIO * n_train)\n",
        "    sub_idx = np.random.choice(np.arange(n_train), size=sub_size, replace=True)\n",
        "    train_subset = torch.utils.data.Subset(train_dataset_global, sub_idx)\n",
        "\n",
        "    train_loader_expert = DataLoader(\n",
        "        train_subset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "        num_workers=NUM_WORKERS, pin_memory=True\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.AdamW(expert.parameters(), lr=LR_EXPERT, weight_decay=1e-4)\n",
        "\n",
        "    # Trial training\n",
        "    for epoch in range(1, TRIAL_EPOCHS + 1):\n",
        "        t_loss, t_acc = train_one_epoch_single_model(expert, train_loader_expert, optimizer, criterion_ce, device, LAMBDA_GL)\n",
        "        v_loss, v_acc = evaluate_single_model(expert, val_loader_global, criterion_ce, device)\n",
        "        print(f\"[Trial {epoch}/{TRIAL_EPOCHS}] Train={t_acc:.3f}, Val={v_acc:.3f}\")\n",
        "\n",
        "    # Full training\n",
        "    for epoch in range(1, FULL_EPOCHS + 1):\n",
        "        t_loss, t_acc = train_one_epoch_single_model(expert, train_loader_expert, optimizer, criterion_ce, device, LAMBDA_GL)\n",
        "        v_loss, v_acc = evaluate_single_model(expert, val_loader_global, criterion_ce, device)\n",
        "        print(f\"[Full {epoch}/{FULL_EPOCHS}] Train={t_acc:.3f}, Val={v_acc:.3f}\")\n",
        "\n",
        "    expert_val_scores.append(v_acc)\n",
        "\n",
        "print(\"\\nValidation scores:\", expert_val_scores)\n",
        "\n",
        "# ================================================================\n",
        "#  PRUNE EXPERTS (with rollback if accuracy collapses)\n",
        "# ================================================================\n",
        "for i, expert in enumerate(experts):\n",
        "    print(f\"\\n=== Pruning Expert {i+1} ===\")\n",
        "    before_params = count_params(expert)\n",
        "    pre_val = expert_val_scores[i]\n",
        "    before_state = copy.deepcopy(expert.state_dict())  # save pre-prune weights\n",
        "\n",
        "    structured_channel_prune(expert, PRUNE_AMOUNT)\n",
        "    after_params = count_params(expert)\n",
        "    print(f\"Params: {before_params/1e6:.2f}M → {after_params/1e6:.2f}M\")\n",
        "\n",
        "    optimizer = torch.optim.AdamW(expert.parameters(), lr=LR_EXPERT)\n",
        "    t_loss, t_acc = train_one_epoch_single_model(\n",
        "        expert, train_loader_global, optimizer, criterion_ce, device, lambda_gl=0.0\n",
        "    )\n",
        "    v_loss, v_acc = evaluate_single_model(expert, val_loader_global, criterion_ce, device)\n",
        "    print(f\"After prune FT: Train={t_acc:.3f}, Val={v_acc:.3f}\")\n",
        "\n",
        "    # If pruning hurts too much, revert\n",
        "    if v_acc < pre_val * 0.95:\n",
        "        print(f\"Pruning degraded Expert {i+1} too much (pre_val={pre_val:.3f}), reverting weights.\")\n",
        "        expert.load_state_dict(before_state)\n",
        "        # keep original expert_val_scores[i]\n",
        "    else:\n",
        "        print(f\"Pruning accepted for Expert {i+1}.\")\n",
        "        expert_val_scores[i] = v_acc  # update to post-prune val if good\n",
        "\n",
        "# ================================================================\n",
        "#  FOREST WEIGHTS\n",
        "# ================================================================\n",
        "val_scores = np.array(expert_val_scores)\n",
        "forest_weights = val_scores / val_scores.sum() if val_scores.sum() > 0 else np.ones_like(val_scores) / len(val_scores)\n",
        "forest_weights = torch.tensor(forest_weights, dtype=torch.float32, device=device)\n",
        "print(\"\\nForest Weights:\", forest_weights.cpu().tolist())\n",
        "\n",
        "def forest_logits(experts, images, weights=None):\n",
        "    for m in experts:\n",
        "        m.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = torch.stack([m(images) for m in experts])\n",
        "    if weights is None:\n",
        "        return logits.mean(0)\n",
        "    return (logits * weights.view(-1, 1, 1)).sum(0)\n",
        "\n",
        "# ================================================================\n",
        "#  STUDENT MODEL (MobileNetV3)\n",
        "# ================================================================\n",
        "def build_student_model(num_classes):\n",
        "    m = models.mobilenet_v3_small(\n",
        "        weights=models.MobileNet_V3_Small_Weights.IMAGENET1K_V1\n",
        "    )\n",
        "    in_features = m.classifier[-1].in_features\n",
        "    m.classifier[-1] = nn.Linear(in_features, num_classes)\n",
        "    return m.to(device)\n",
        "\n",
        "student = build_student_model(NUM_CLASSES)\n",
        "print(\"Student params:\", count_params(student)/1e6, \"M\")\n",
        "\n",
        "def kd_loss_fn(s_logits, t_logits, labels, T, alpha):\n",
        "    ce = criterion_ce(s_logits, labels)\n",
        "    log_p_s = F.log_softmax(s_logits / T, dim=1)\n",
        "    p_t = F.softmax(t_logits / T, dim=1)\n",
        "    kd = F.kl_div(log_p_s, p_t, reduction=\"batchmean\") * (T**2)\n",
        "    return alpha * ce + (1 - alpha) * kd, ce, kd\n",
        "\n",
        "optimizer_student = torch.optim.AdamW(student.parameters(), lr=LR_STUDENT)\n",
        "\n",
        "print(\"\\n=== TRAINING STUDENT WITH KD ===\")\n",
        "for epoch in range(1, KD_EPOCHS + 1):\n",
        "    student.train()\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader_global:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            t_logits = forest_logits(experts, images, weights=forest_weights)\n",
        "\n",
        "        optimizer_student.zero_grad()\n",
        "        s_logits = student(images)\n",
        "        loss, ce, kd = kd_loss_fn(s_logits, t_logits, labels, KD_TEMPERATURE, KD_ALPHA)\n",
        "        loss.backward()\n",
        "        optimizer_student.step()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        total_correct += (s_logits.argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = total_correct / total\n",
        "    val_acc = evaluate_single_model(student, val_loader_global, criterion_ce, device)[1]\n",
        "\n",
        "    print(f\"[KD {epoch}/{KD_EPOCHS}] Train Acc={train_acc:.3f}, Val Acc={val_acc:.3f}\")\n",
        "\n",
        "# ================================================================\n",
        "#  TEST ACCURACY\n",
        "# ================================================================\n",
        "test_acc = evaluate_single_model(student, test_loader_global, criterion_ce, device)[1]\n",
        "print(\"\\nFinal Student Test Accuracy:\", test_acc)\n",
        "print(\"Forest params:\", sum(count_params(e) for e in experts)/1e6, \"M\")\n",
        "print(\"Student params:\", count_params(student)/1e6, \"M\")\n"
      ]
    }
  ]
}